<a name="top"></a>

<p align="right">
  <a href="https://github.com/ramaaorella/final_disenio/blob/main/add-process/design-iterations/iteration-1.md"><i><< Volver a la Iteración 1</i></a>
  &nbsp;&nbsp;|&nbsp;&nbsp;
  <a href="https://github.com/ramaaorella/final_disenio#proceso-add-e-iteraciones"> Volver al índice</a> 
</p>

## ADR 005: Optimización de la latencia de red y reducción de sobrecarga mediante protocolos livianos, reducción de mensajes y co-locación de recursos

Nuevamente, en favor de garantizar una experiencia fluida para los usuarios y un procesamiento eficiente de mensajes, se opta por implementar estrategias para optimizar la latencia de red y reducir la sobrecarga en el sistema.

### Decision

Se decide priorizar el uso de protocolos de comunicación livianos para optimizar la latencia de red y mejorar la capacidad de respuesta del sistema. Si bien ya se eligió Websocket como protocolo de comunicación entre el Core y el Frontend por su eficiencia y capacidad para una comunicación bidireccional en tiempo real, esta elección igualmente ya está en línea con esta necesidad de emplear protocolos ágiles para una comunicación eficaz. Para la comunicación entre el Gateway de mensajería y el Core, sin embargo, aún no se ha determinado el protocolo específico a utilizar. Se requiere que este protocolo cumpla con la característica de ser liviano para garantizar una comunicación eficiente y ágil.

Asimismo, se establece la necesidad de minimizar la carga de datos transmitidos eliminando toda información innecesaria de los mensajes. Es responsabilidad del Gateway de mensajería reducir los mensajes recibidos a la información necesaria para el funcionamiento óptimo del sistema. Esto contribuirá a reducir la latencia y mejorar la eficiencia en la transmisión de mensajes.

Se decide implementar también un sistema de caché para almacenar localmente la lista de usuarios en línea en el SpecialIntegrationService. Esta decisión se basa en la necesidad de evitar consultas repetitivas al WebsocketManager ante cada mensaje entrante para determinar si debe priorizarse. Manteniendo una copia actualizada de la lista de usuarios en línea en la caché, se logra reducir significativamente la latencia en la determinación de la disponibilidad de usuarios y se mejora la eficiencia en la gestión de mensajes, lo que conduce a una mayor velocidad en el procesamiento de los mismos.

Por último, se decide priorizar la estrategia de co-locación de recursos para los componentes vinculados a los flujos de mensajes entrantes y salientes, con el objetivo de minimizar la latencia y mejorar el rendimiento del sistema. Dada la naturaleza crítica de los flujos de mensajes y la arquitectura del sistema (que si bien inicialmente sugiere un despliegue 3-tier por la estructura definida, eventualmente podría desplegarse de forma distribuida), es necesario mantener presente la co-localización de estos componentes como requisito clave para garantizar una comunicación eficiente y una respuesta rápida del sistema ante las interacciones de los usuarios. Aunque la falta de datos sobre la carga del sistema dificulta una planificación detallada en esta etapa inicial, se reconoce la necesidad de optimizar la comunicación entre las instancias de los servicios SpecialIntegrationService, MessageService y WebsocketManager para un flujo eficiente de mensajes entrantes y salientes, que ayude a reducir la latencia y mejorar la velocidad de procesamiento de los mismos. De igual manera, sería deseable que los componentes del Gateway de mensajería se mantengan también en proximidad física o lógica.

### Rationale

La optimización de la latencia de red tiene como objetivo principal reducir el tiempo necesario para la transmisión de datos entre los diferentes componentes del sistema, lo que a su vez acelera el procesamiento de mensajes y mejora la capacidad de respuesta del sistema en su conjunto.

En primer lugar, la implementación de protocolos livianos es fundamental para reducir la sobrecarga de red y mejorar el rendimiento del sistema. Se elige este tipo de protocolos al estar optimizados para entornos de red de baja latencia y ancho de banda limitado, lo que los hace ideales para aplicaciones donde se requiere una alta velocidad de entrega de mensajes y una baja sobrecarga de red.

La eliminación de información innecesaria en los mensajes también contribuye a minimizar el uso de recursos y mejorar el rendimiento del sistema. Al transmitir únicamente la información esencial requerida para cada mensaje, se reduce significativamente la cantidad de datos transmitidos a través de la red, lo que disminuye la carga de trabajo en los componentes de red y mejora la eficiencia general del sistema.

Por su parte, la implementación de una caché para almacenar la lista de usuarios en línea permite mejorar la velocidad de procesamiento de los mensajes. Al almacenar localmente esta información en el SpecialIntegrationService, se evitan consultas repetitivas al WebsocketManager, lo que agiliza el proceso de enrutamiento de mensajes. Esto conduce a una respuesta más rápida y eficiente del sistema ante las interacciones de los usuarios, contribuyendo así a una experiencia de usuario más fluida.

Por último, la co-locación de recursos contribuye a reducir la latencia al permitir que los componentes críticos se ejecuten en la misma infraestructura física o virtual. Esto minimiza los tiempos de comunicación entre los componentes y optimiza el flujo de datos dentro del sistema. Al tener los recursos relacionados en proximidad física, se reduce la latencia inherente a las comunicaciones entre nodos, lo que resulta en una mejora notable en la capacidad de respuesta del sistema y en la experiencia del usuario. Sin embargo, la implementación de la co-locación requiere una planificación estratégica según los requisitos del sistema, así como una evaluación continua para garantizar su efectividad y eficiencia a lo largo del tiempo.

### Alternatives considered

Para abordar la optimización de la latencia de red y mejorar la capacidad de respuesta del sistema, se consideraron diversas alternativas.

En cuanto a la optimización de la latencia de red y mejora de la capacidad de respuesta del sistema, se contemplaron opciones que incluían el uso de protocolos de comunicación más tradicionales o pesados, como HTTP. Sin embargo, estas alternativas fueron descartadas debido a su potencial impacto en la latencia y la eficiencia del sistema.

Para minimizar la carga de datos transmitidos, se exploraron otras estrategias como la compresión de mensajes o la fragmentación de datos, pero dado que los mensajes no suelen contener una cantidad significativa de datos redundantes o repetitivos que puedan ser comprimidos, y considerando que la fragmentación de datos podría introducir complejidad adicional sin proporcionar beneficios significativos, se optó por la eliminación de información innecesaria como la estrategia más efectiva para optimizar el rendimiento del sistema.

Antes de decidir implementar una caché para almacenar la lista de usuarios en línea, se consideraron alternativas como mejorar la eficiencia de las consultas al WebsocketManager o utilizar estructuras de datos más eficientes. Sin embargo, no había mucho espacio a mejora y además estas opciones aún implicaban realizar consultas ante cada mensaje, lo que resulta en un impacto negativo en la latencia y la velocidad de procesamiento de los mensajes. Por lo tanto, se optó por la implementación de una caché, que permite reducir la dependencia de consultas repetitivas al WebsocketManager y mejorar la eficiencia en la gestión de usuarios en línea.

Finalmente, de forma complementaria a la estrategia de co-locación de recursos, se consideraron otras tácticas, como la distribución geográfica de los servidores o la optimización de los algoritmos de enrutamiento. Sin embargo, debido a la falta de una comprensión clara de la carga a la que se enfrentará el sistema, resulta difícil tomar decisiones sobre estas opciones alternativas. Se optó por mantener la consideración de la co-locación de recursos para ser retomada más adelante en la implementación y despliegue del sistema. Esto se debe a que el sistema prevé desplegar sus servicios en entornos diferentes, y sin una estrategia y planificación clara, esta distribución puede tener un impacto significativo en la latencia de los mensajes y la experiencia del usuario. Por lo tanto, es prudente mantener esta estrategia en consideración para ser abordada en etapas posteriores, cuando se disponga de información más detallada sobre la carga del sistema y se pueda planificar su implementación con mayor precisión.

### Status

Accepted

### Consequences

- La reducción de la latencia en la transmisión de mensajes se traduce en una experiencia de usuario más fluida y tiempos de carga más rápidos.
- La implementación de protocolos de comunicación livianos mejora el rendimiento del sistema al reducir la carga en la red y agilizar los tiempos de respuesta.
- La eliminación de información innecesaria en los mensajes optimiza el uso de recursos del sistema y facilita una gestión más efectiva de los datos.
- La implementación de una caché para almacenar la lista de usuarios en línea reduce la latencia en la determinación de la prioridad de los mensajes, mejorando la eficiencia en la gestión y el procesamiento de los mismos.
- La posible co-locación de recursos podría contribuir a minimizar los tiempos de comunicación entre componentes, mejorando así la eficiencia del sistema.

<p align="right">(<a href="#top">Volver al inicio</a>)</p>

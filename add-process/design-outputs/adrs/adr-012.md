<a name="top"></a>

<p align="right">
  <a href="https://github.com/ramaaorella/final_disenio/blob/main/add-process/design-iterations/iteration-2.md"><i><< Volver a la Iteración 2</i></a>
  &nbsp;&nbsp;|&nbsp;&nbsp;
  <a href="https://github.com/ramaaorella/final_disenio#proceso-add-e-iteraciones"> Volver al índice</a> 
</p>

## ADR 012: Implementación de estrategias de escalado automático y balanceo de carga

Dado que se ha optado por encapsular los servicios en contenedores y orquestarlos para simplificar el escalado, surge la cuestión de si es necesario establecer estrategias y la infraestructura necesaria para automatizar la escalabilidad del sistema en base a la carga. La automatización del escalado podría proporcionar una respuesta más ágil, una mayor disponibilidad y una mejora en el throughput del sistema al permitir que ajuste dinámicamente su capacidad según sea necesario. Sin embargo, es importante considerar que la implementación de estas estrategias de escalado automático conlleva costos adicionales asociados a la infraestructura y a la configuración de las herramientas necesarias.

Además, para asegurar que el sistema pueda adaptarse efectivamente a cambios en la carga de trabajo y operar de manera eficiente, se analizarán las partes de la arquitectura propensas al escalado horizontal para poder identificar los puntos críticos en donde distribuir equitativamente la carga entre las instancias replicadas será crucial (ya que la mera replicación de servicios no garantiza automáticamente una mejora en el rendimiento). Cuando el escalado horizontal se acompaña de una distribución equitativa, se logra una óptima utilización de los recursos y una respuesta ágil del sistema ante fluctuaciones en la carga. Esto ayuda a evitar posibles cuellos de botella y maximiza el rendimiento general del sistema.

### Decision

Se decide implementar estrategias de escalado automático utilizando Kubernetes Event-Driven Autoscaling (KEDA) junto con Horizontal Pod Autoscaler (HPA). Para extender la infraestructura de Kubernetes con recursos de la nube de manera transparente y facilitar la gestión del clúster híbrido, se incorporará Virtual Kubelet.

Además, se incorporarán cuatro balanceadores de carga para optimizar la distribución de la carga en el sistema: el primero actuará como puerta de entrada a los brokers MQTT, utilizando HAProxy para gestionar el tráfico de conexiones y mensajes de alta concurrencia; el segundo se integrará al API Gateway para distribuir de manera equitativa la carga entre los servicios del Core a través de enrutamiento interno; el tercero se ubicará al frente del Gateway de Mensajería para balancear la carga de los mensajes provenientes de las APIs externas cuando su volumen supere la capacidad del Gateway; y el cuarto, de ser necesario a futuro, se añadirá del lado del cliente para manejar el volumen creciente de solicitudes cuando la capacidad del API Gateway se vea superada. Esta estrategia permitirá una distribución eficiente de las solicitudes y mensajes, optimizando el rendimiento del sistema y garantizando su capacidad de respuesta ante picos de demanda tanto internos como externos.

### Rationale

El sistema debe facilitar el escalado ante la variabilidad de distintos factores: un aumento en el número de clientes (operadores), un incremento en el procesamiento por mensaje, un mayor volumen de mensajes entrantes y/o salientes, así como una ampliación de la cantidad de canales soportados, entre otros. De todos esos factores, se considera al aumento en el volumen de mensajes como el más impredecible, dado al carácter esporádico propio de la comunicación en sistemas de mensajería en tiempo real, que dificulta el poder anticiparse y estimar con precisión el volumen de mensajes a soportar. Es por ello que se decidió la implementación de estrategias de escalado que permitan hacerlo de forma automática (concretamente mediante KEDA), ya que además de brindar una respuesta ágil a los cambios en la carga de trabajo, previene situaciones críticas donde el sistema podría verse sobrecargado y expuesto a la pérdida de mensajes, lo cual resultaría en consecuencias irreversibles si no aborda ese escalado de recursos de alguna forma.

La implementación de estrategias de escalado automático mediante KEDA ofrece una solución versátil y adaptable para gestionar dinámicamente la capacidad del sistema en función de la carga de trabajo. KEDA extiende las capacidades del Horizontal Pod Autoscaler (HPA), que se basa principalmente en métricas de CPU y memoria, al permitir el escalado basado en eventos específicos, como el tamaño de las colas de mensajes en RabbitMQ. Esto proporciona una mayor precisión y adaptabilidad a las cargas de trabajo impulsadas por eventos. De esta manera, se evitan las limitaciones de un escalado basado únicamente en métricas más básicas, permitiendo que otros factores que también afectan la capacidad de los recursos sean considerados.

Además, la implementación de estrategias de escalado automático no sólo permite ajustar dinámicamente la capacidad del sistema en función de la carga de trabajo, sino que también facilita la reducción de recursos cuando la demanda disminuye, lo que conlleva a un uso más eficiente de los recursos y ahorro de costos.

Sin embargo, es importante considerar que el sistema está diseñado para desplegarse inicialmente en una infraestructura on-premise, con la posibilidad de extender su capacidad con recursos de la nube cuando la carga sea demasiado alta, evolucionando a una infraestructura híbrida. Para ello, se utilizará el Virtual Kubelet como capa de abstracción para permitir que los nodos locales puedan expandirse hacia la nube sin la necesidad de reconfigurar los servicios y adaptarse automáticamente a nuevas capacidades sin intervención manual. Este enfoque permitirá gestionar de forma más eficiente los recursos entre la infraestructura local y la nube, según la demanda.

Aún cuando las estrategias de escalado automático logren escalar eficientemente el sistema para afrontar la demanda variable, es necesario asegurar la buena distribución de esa demanda entre los diferentes componentes del sistema para evitar posibles cuellos de botella y maximizar el rendimiento general. Es por ello que se opta por considerar la incorporación de balanceadores de carga en el diseño de la arquitectura del sistema.

Evaluando qué componentes del sistema pueden llegar a escalar, se identificaron cuatro puntos en los que el sistema puede beneficiarse de incluir balanceadores de carga:

- <ins>Puerta de entrada a los brokers MQTT:</ins> Dado que los brokers MQTT manejarán una gran cantidad de conexiones simultáneas y tráfico de mensajes, es crucial distribuir esta carga de manera eficiente. HAProxy se elige para este balanceador debido a su alta performance y capacidad de manejar grandes volúmenes de tráfico, proporcionando una solución robusta y escalable.

- <ins>Gateway y distribución de carga entre los servicios del Core:</ins> El Gateway actúa como un punto central para las solicitudes entrantes y necesita distribuir eficientemente estas solicitudes entre los servicios del Core. La integración de un balanceador de carga en esta etapa asegura que la carga se distribuya equitativamente, optimizando el rendimiento y evitando sobrecargas en servicios específicos. En este caso, se considera que el propio Gateway debe asumir la responsabilidad de distribuir las solicitudes de forma eficiente entre los servicios, aprovechando estrategias de enrutamiento interno. </br>
  Respecto a las conexiones WebSocket, se busca evitar que el API Gateway asuma una carga excesiva, especialmente si el volumen de usuarios en línea crece significativamente. En lugar de que el Gateway se encargue directamente de gestionar y balancear las conexiones WebSocket, la responsabilidad se delega al Sessions Service (<a href="https://github.com/ramaaorella/final_disenio/blob/main/add-process/design-outputs/adrs/adr-014.md">ADR-014</a>). Este servicio centraliza la información sobre los canales WebSocket, incluyendo la cantidad de conexiones y la carga de las instancias de WebSocketManager. Así, el API Gateway consulta al Sessions Service para determinar a qué instancia de WebSocketManager debe redirigir al cliente, asegurando que el balanceo de carga de las conexiones WebSocket quede desacoplado del API Gateway, permitiendo una mejor escalabilidad y evitando que este se sobrecargue.

- <ins>Balanceador de carga del Gateway de Mensajería:</ins> Cuando el volumen de mensajes provenientes de las APIs externas supere la capacidad del Gateway de Mensajería, se requerirá un balanceador de carga adicional al frente de este componente. Esto permitirá distribuir de manera más eficiente el tráfico de mensajes, evitando posibles cuellos de botella y asegurando que el sistema pueda manejar picos de demanda sin comprometer su rendimiento.

- <ins>Balanceador de carga del lado del cliente (frontend):</ins> A medida que el volumen de clientes crece y supera la capacidad de procesamiento del gateway, puede llegar a ser necesaria la incorporación de un balanceador de carga del lado del cliente (frontend). Esto ayudará a distribuir las solicitudes de manera más efectiva, garantizando una experiencia de usuario fluida y consistente, incluso durante picos de alta demanda.

Si bien en los cuatro casos el sistema se beneficiaría de balanceadores de carga cuando la carga del sistema sea alta, sólo se considera necesario un balanceador de carga dedicado en el primer punto (la puerta de entrada a los brokers MQTT). En los demás casos, se considera suficiente con implementar estrategias de enrutamiento interno que tengan en cuenta la existencia de más servicios capaces de distribuir las solicitudes de manera equitativa. Esta lógica de distribución debe ser lo más simple posible para evitar sobrecargar el sistema con latencia adicional en el procesamiento de mensajes.

### Alternatives considered

En primer lugar, se contempló la posibilidad de optar por un enfoque de escalado manual, donde se requiere de un monitoreo manual de la carga de trabajo para realizar ajustes en los recursos del sistema según sea necesario. Aunque este método ofrece un control más directo sobre el escalado, también conlleva el riesgo de una respuesta más lenta a los cambios en la carga de trabajo y una mayor probabilidad de errores humanos. Además, la escalabilidad manual puede resultar menos eficiente en entornos con fluctuaciones rápidas o impredecibles en la demanda, por lo que ante la posibilidad de exponerse a la pérdida de mensajes por una sobrecarga del sistema, se descartó esta alternativa en favor de estrategias de escalado automático.

En segundo lugar, se consideró la opción de utilizar Horizontal Pod Autoscaler (HPA) como alternativa inicial a KEDA para implementar estrategias de escalado automático en el sistema de Kubernetes. Si bien HPA es una herramienta sólida y ampliamente utilizada para escalar los pods de manera automática en función de las métricas de recursos como CPU y memoria, su capacidad se limita a estas métricas básicas. Esto podría resultar insuficiente para adaptarse de manera óptima a las fluctuaciones de la carga de trabajo impulsadas por eventos específicos, como el tamaño de las colas de mensajes en RabbitMQ. Dado que KEDA extiende las capacidades de HPA al permitir el escalado basado en eventos específicos, se determinó que la combinación de ambas herramientas ofrecería una solución más precisa y adaptable para gestionar dinámicamente la capacidad del sistema.

Por último, se consideró evitar la incorporación del balanceo de carga para no impactar sobre la latencia y el throughput de los mensajes. Sin embargo, al estar la posibilidad bastante probable de que el sistema escale, resulta casi fundamental garantizar la distribución equitativa de la carga entre los diferentes componentes del sistema para evitar posibles cuellos de botella y maximizar el rendimiento general. De no hacerlo, se corre el riesgo de que ciertos componentes del sistema se vean sobrecargados mientras otros permanecen subutilizados, lo que podría resultar en una experiencia deficiente para los usuarios finales y en un desperdicio de recursos disponibles.

Para el balanceador de carga dedicado como puerta de entrada a los brokers MQTT, se consideraron varias alternativas, entre ellas NGINX y Envoy Proxy. NGINX es reconocido por su versatilidad como servidor web y también como un proxy inverso al que se le puede atribuir el balanceo de carga. Sin embargo, su rendimiento en situaciones de tráfico extremadamente elevado y conexiones simultáneas masivas puede verse limitado en comparación con soluciones más especializadas. Envoy Proxy, por su parte, está diseñado para entornos modernos de microservicios y contenedores, siendo una excelente opción para manejar comunicaciones en arquitecturas distribuidas. Sin embargo, en este caso específico, Envoy se descarta debido a que su complejidad y la sobrecarga de recursos necesarios para una correcta implementación y gestión no se justifican para el caso de uso de balanceo de carga a gran escala, donde la simplicidad y eficiencia en el manejo de tráfico masivo son prioritarias. En este contexto, HAProxy se destaca como la opción más adecuada, ya que ofrece una alta capacidad de rendimiento, estabilidad y eficiencia en el balanceo de grandes volúmenes de conexiones simultáneas, y con menor complejidad operativa.

### Status

Accepted

### Consequences

- La implementación de estrategias de escalado automático y balanceo de carga mejora la agilidad, disponibilidad y eficiencia del sistema al ajustar dinámicamente su capacidad según la carga de trabajo.

- La implementación de balanceadores de carga y estrategias de enrutamiento interno aseguran una distribución equitativa de la carga, optimizando el rendimiento del sistema y la experiencia del usuario.

- Considerar una infraestructura híbrida para las estrategias de escalado asegura una gestión eficiente de recursos en entornos locales y en la nube, preparando al sistema para futuros crecimientos.

<p align="right">(<a href="#top">Volver al inicio</a>)</p>
